name: Deploy Docs to GitHub Pages

defaults:
  run:
    working-directory: web

on:
  push:
    branches:
      - main
      - feat/docs
    paths:
      - 'web/**'

jobs:
  deploy:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
        with:
          version: latest

      - name: Use Node.js LTS
        uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'pnpm'
          cache-dependency-path: web/pnpm-lock.yaml

      - name: Install dependencies
        run: pnpm install
      - name: Build website
        run: pnpm run build

      # Popular action to deploy to GitHub Pages:
      # Docs: https://github.com/peaceiris/actions-gh-pages#%EF%B8%8F-docusaurus
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          # Build output to publish to the `gh-pages` branch:
          publish_dir: ./web/build
          # The following lines assign commit authorship to the official
          # GH-Actions bot for deploys to `gh-pages` branch:
          # https://github.com/actions/checkout/issues/13#issuecomment-724415212
          # The GH actions bot is used by default if you didn't specify the two fields.
          # You can swap them out with your own user credentials.
          user_name: github-actions[bot]
          user_email: 41898282+github-actions[bot]@users.noreply.github.com

  algolia-recrawl:
    name: Algolia Recrawl
    needs: deploy
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      # We don't know when the site will be deployed, we just wait a few seconds
      # Better solutions can be found
      - name: Sleep for 30s
        run: sleep 30

      - name: Algolia reindex
        env:
          CRAWLER_USER_ID: ${{ secrets.CRAWLER_USER_ID }}
          CRAWLER_API_KEY: ${{ secrets.CRAWLER_API_KEY }}
          CRAWLER_ID: ${{ secrets.CRAWLER_ID }}
        run: |
          sudo apt update -y && sudo apt install -y curl
          curl -H "Content-Type: application/json" \
            --user "${CRAWLER_USER_ID}:${CRAWLER_API_KEY}" \
            -X POST \
            "https://crawler.algolia.com/api/1/crawlers/${CRAWLER_ID}/reindex"
